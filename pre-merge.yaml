steps:
- id: 'branch-name'
  name: 'alpine'
  waitFor: ['-']
  entrypoint: 'sh'
  args:
    - '-c'
    - |
      echo  echo "*****************************TEST DAGS**************************************************************************"
      echo "HEAD BRANCH_NAME: $_HEAD_BRANCH -- BASE BRANCH_NAME:$_BASE_BRANCH -- SHORT_SHA - ${SHORT_SHA} PROJECT_ID: $PROJECT_ID"
      echo "***********************************************************************************************************************"

- id: 'make-env-substitutions'
  name: 'ubuntu'
  waitFor: ['-']
  args: ['bash', './env_subst.sh','apply', '/workspace/infra_build', '$PROJECT_ID', '${_COMPOSER_LOCATION}', '$PROJECT_ID']

- id: 'setup-repos'
  name: 'hashicorp/terraform:1.2.4'
  waitFor: ['make-env-substitutions']
  dir: './infra_build'
  entrypoint: 'sh'
  args:
  - '-c'
  - |
    terraform init
    terraform workspace select $PROJECT_ID || terraform workspace new $PROJECT_ID
    terraform apply --auto-approve

- id: 'copy-dags-to-data-bucket-for-testing'
  name: gcr.io/cloud-builders/gcloud
  waitFor: ['setup-repos']
  entrypoint: 'sh'
  args:
  - '-c'
  - |
    bucket=$(gcloud composer environments describe $PROJECT_ID --location ${_COMPOSER_LOCATION}|grep dagGcsPrefix|cut -d ":" -f2-3)
    echo "BUCKET=$bucket"  
    gsutil --version

- id: 'build-test-container'
  name: 'gcr.io/kaniko-project/executor:latest'
  waitFor: ['setup-repos']
  args:
    - --destination=${_COMPOSER_LOCATION}-docker.pkg.dev/${PROJECT_ID}/airflow-test-container/aftest
    - --cache=true
    - --cache-ttl=240h

- id: 'run-unit-test'
  name: '${_COMPOSER_LOCATION}-docker.pkg.dev/${PROJECT_ID}/airflow-test-container/aftest:latest'
  waitFor: ['build-test-container']
  entrypoint: 'sh'
  args:
    - '-c'
    - |
      pytest /workspace/tests
options:
    dynamic_substitutions: true
substitutions:
  _COMPOSER_LOCATION: europe-west2
  _COMPOSER_BUCKET: